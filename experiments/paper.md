# 小论文——基于深度强化学习的Coflow调度

## 摘要


## Introduction
随着大数据计算的流行，数据中心中的应用从传统的点对点应用逐渐向多对多的大数据计算应用转变，这种变化在数据中心网络中表现为，出现有语义相关性的并行流，这种并行流成为coflow。

传统的数据中心网络优化大多基于数据包、流，DCN无法感知到大数据计算过程中的并行计算目的，为了实现网络对应用数据传输新模式的感知，近些年来，一些学者研究如何在coflow的基础上对数据中心网络优化，包括Varys、Aalo、Dark等。

Aalo、Dark的以Coflow作为调度的基本单元，采用最少获得服务优先（LAS）的方法，实现了高效的调度效率，使得应用的作业完成时间更短，提升了应用的数据传输性能。

`对coflow直接使用LAS过于繁杂`，Aalo采用多级反馈队列MLFQ模型，根据MLFQ各个队列的阈值，将coflow按照coflow的已发送长度划分为多个优先级，高优先级先发送，低优先级后发送，从而用更简单的代价实现高性能的coflow调度。

然而不同的网络场景中coflow的分布往往不同，不同的网络场景需要不同的MLFQ队列阈值来划分优先级，在动态变化的网络环境下，一组合适的MLFQ阈值往往也是动态变化的，因此，这就需要能够实时计算出一组合适的阈值。

DRL是机器学习领域中处理序列决策的方法，最近一些学者研究如何应用DRL进行网络调度，AuTO、Decima、MVFST-RL等。本文利用DRL通过对MLFQ状态的学习，生成合适的队列阈值，使得队列阈值能够更好的划分coflow的优先级，从而降低coflow的平均完成时间。

在本文中，我们介绍了常用的coflow调度模型，设计了DRL的状态、动作、奖励，使用LSTM优化DDPG算法，`××××`，实验中的训练结果表明，。。。

## related work


## Coflow调度模型

1. LAS调度

2. MLFQ优化

## DRL优化参数

1. 基本的DDPG算法设计

2. LSTM优化

3. ××××优化

## 实验

数据：Facebook数据集
实验对比：Aalo、Varys

## 结论


## 参考文献

